<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Onramp Professional KYC</title>
    <script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/babel-standalone@6/babel.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style> 
        body { font-family: 'Inter', sans-serif; background-color: #F8FAFC; }
        .chat-anim { animation: slideIn 0.3s ease-out; }
        @keyframes slideIn { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }
    </style>
</head>
<body>
    <div id="root"></div>
    <script type="text/babel">
        const { useState, useEffect, useRef } = React;

        const StatusBadge = ({ status }) => {
            const colors = { ACTIVE: 'bg-blue-100 text-blue-800', APPROVED: 'bg-green-100 text-green-800', REJECTED: 'bg-red-100 text-red-800' };
            return <span className={`px-2 py-1 rounded text-xs font-bold ${colors[status] || 'bg-gray-100'}`}>{status}</span>;
        };

        function App() {
            const [view, setView] = useState('KYC');
            const [sessionId, setSessionId] = useState(null);
            const [status, setStatus] = useState("IDLE");
            const [transcript, setTranscript] = useState([]);
            const [processing, setProcessing] = useState(false);
            const [warning, setWarning] = useState(null);
            
            const videoRef = useRef(null);
            const mediaRecorderRef = useRef(null);
            const chunksRef = useRef([]);

            // Speech Synthesis
            const speak = (text) => {
                window.speechSynthesis.cancel();
                const u = new SpeechSynthesisUtterance(text);
                u.onend = () => startListening(); 
                window.speechSynthesis.speak(u);
            };

            // Speech Recognition
            const startListening = () => {
                if(status !== 'ACTIVE' && status !== 'IDLE') return;
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                if (!SpeechRecognition) return alert("Browser not supported");
                
                const recognition = new SpeechRecognition();
                recognition.continuous = false;
                recognition.onresult = (e) => handleUserResponse(e.results[0][0].transcript);
                recognition.start();
            };

            const startSession = async (lang) => {
                setStatus("ACTIVE");
                initCamera();
                const res = await fetch('/api/start', { 
                    method: 'POST', 
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({ language: lang })
                });
                const data = await res.json();
                setSessionId(data.sessionId);
                addToTranscript('AI', data.next_question);
                speak(data.next_question);
                startRecording();
            };

            const handleUserResponse = async (text) => {
                addToTranscript('USER', text);
                setProcessing(true);
                const res = await fetch('/api/process', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({ sessionId, userText: text })
                });
                const data = await res.json();
                setProcessing(false);
                
                addToTranscript('AI', data.next_question);
                
                if (data.kyc_status !== 'CONTINUE') {
                    setStatus(data.kyc_status);
                    stopRecording();
                }
                speak(data.next_question);
            };

            const initCamera = async () => {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                videoRef.current.srcObject = stream;
                // Start Vision Check Loop
                setInterval(() => checkVision(), 4000);
            };

            const checkVision = async () => {
                if(!videoRef.current) return;
                const canvas = document.createElement('canvas');
                canvas.width = 320; canvas.height = 240;
                canvas.getContext('2d').drawImage(videoRef.current, 0, 0, 320, 240);
                
                const res = await fetch('/api/vision-check', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({ image: canvas.toDataURL('image/jpeg', 0.5), sessionId })
                });
                const data = await res.json();
                if(data.message) {
                    setWarning(data.message);
                    setTimeout(() => setWarning(null), 3000);
                }
            };

            const startRecording = () => {
                const stream = videoRef.current.srcObject;
                const recorder = new MediaRecorder(stream, { mimeType: 'video/webm' });
                chunksRef.current = [];
                recorder.ondataavailable = e => chunksRef.current.push(e.data);
                recorder.start();
                mediaRecorderRef.current = recorder;
            };

            const stopRecording = () => {
                const recorder = mediaRecorderRef.current;
                if(!recorder) return;
                recorder.onstop = () => {
                    const blob = new Blob(chunksRef.current, { type: 'video/webm' });
                    const formData = new FormData();
                    formData.append("video", blob);
                    formData.append("sessionId", sessionId);
                    fetch('/api/upload-video', { method: 'POST', body: formData });
                };
                recorder.stop();
            };

            const addToTranscript = (sender, text) => {
                setTranscript(prev => [...prev, { sender, text, time: new Date().toLocaleTimeString() }]);
            };

            return (
                <div className="h-screen flex flex-col md:flex-row overflow-hidden">
                    {/* LEFT PANEL: VIDEO */}
                    <div className="md:w-1/2 bg-slate-900 relative flex items-center justify-center">
                        {warning && <div className="absolute top-10 z-20 bg-red-600 text-white px-6 py-2 rounded-full shadow-lg font-bold animate-bounce">{warning}</div>}
                        <video ref={videoRef} autoPlay muted className="w-full h-full object-cover opacity-80"></video>
                        <div className="absolute bottom-10 text-white text-center">
                            <h2 className="text-xl font-bold">{status === 'ACTIVE' ? 'Analyzing Environment...' : 'Ready for Verification'}</h2>
                        </div>
                    </div>

                    {/* RIGHT PANEL: CHAT */}
                    <div className="md:w-1/2 bg-white flex flex-col">
                        <div className="p-4 border-b flex justify-between items-center shadow-sm z-10">
                            <h1 className="font-bold text-lg text-slate-800">Onramp<span className="text-blue-600">AI</span> Agent</h1>
                            <StatusBadge status={status} />
                        </div>

                        <div className="flex-1 overflow-y-auto p-6 space-y-4 bg-slate-50">
                            {transcript.map((t, i) => (
                                <div key={i} className={`flex ${t.sender === 'USER' ? 'justify-end' : 'justify-start'} chat-anim`}>
                                    <div className={`max-w-[80%] px-4 py-3 rounded-2xl text-sm ${t.sender === 'USER' ? 'bg-blue-600 text-white rounded-br-none' : 'bg-white border text-slate-700 rounded-bl-none shadow-sm'}`}>
                                        {t.text}
                                    </div>
                                </div>
                            ))}
                            {processing && <div className="text-xs text-slate-400 animate-pulse pl-2">AI is thinking...</div>}
                        </div>

                        <div className="p-6 border-t bg-white">
                            {status === 'IDLE' ? (
                                <button onClick={() => startSession('en-IN')} className="w-full bg-slate-900 text-white py-4 rounded-xl font-bold hover:bg-slate-800 transition shadow-lg">
                                    Start Video Verification
                                </button>
                            ) : (
                                <div className="text-center text-xs text-slate-400">Microphone Active â€¢ Secure Connection</div>
                            )}
                        </div>
                    </div>
                </div>
            );
        }

        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(<App />);
    </script>
</body>
</html>
